{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mask R-CNN - Apply model to hail imagery subsets\n",
    "\n",
    "Code and visualizations to test, debug, and evaluate the Mask R-CNN model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import math\n",
    "import re\n",
    "import time\n",
    "import json\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import skimage\n",
    "\n",
    "from multiprocessing import Pool\n",
    "\n",
    "# Root directory of the project\n",
    "ROOT_DIR = os.path.abspath(\"/home/jsoderho/dev/Mask_RCNN-tfv2\")\n",
    "\n",
    "# Import Mask RCNN\n",
    "sys.path.append(ROOT_DIR)  # To find local version of the library\n",
    "from mrcnn import utils\n",
    "from mrcnn import visualize\n",
    "from mrcnn.visualize import display_images\n",
    "import mrcnn.model as modellib\n",
    "from mrcnn.model import log\n",
    "\n",
    "import hail\n",
    "\n",
    "%matplotlib inline \n",
    "\n",
    "# Directory to save logs and trained model\n",
    "MODEL_DIR = \"/data/hailpixel_20200119\"\n",
    "\n",
    "#path to weights\n",
    "HAIL_WEIGHTS_PATH = \"/data/hailpixel_20200119/mask_rcnn_hail_final.h5\"  # TODO: update this path\n",
    "\n",
    "#path to subset images\n",
    "SUBSET_PATH = '/data/hailpixel_20200119/testing_subset'\n",
    "ROI_PATH    = '/data/hailpixel_20200119/testing_roi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the neural network on.\n",
    "# Useful if you're training a model on the same \n",
    "# machine, in which case use CPU and leave the\n",
    "# GPU for training.\n",
    "DEVICE = \"/cpu:0\"  # /cpu:0 or /gpu:0\n",
    "\n",
    "# Inspect the model in training or inference modes\n",
    "# values: 'inference' or 'training'\n",
    "# TODO: code for 'training' test mode not ready yet\n",
    "TEST_MODE = \"inference\"\n",
    "\n",
    "#load config\n",
    "config = hail.HailConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ax(rows=1, cols=1, size=16):\n",
    "    \"\"\"Return a Matplotlib Axes array to be used in\n",
    "    all visualizations in the notebook. Provide a\n",
    "    central point to control graph sizes.\n",
    "    \n",
    "    Adjust the size attribute to control how big to render images\n",
    "    \"\"\"\n",
    "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configurations:\n",
      "BACKBONE                       resnet101\n",
      "BACKBONE_STRIDES               [4, 8, 16, 32, 64]\n",
      "BATCH_SIZE                     1\n",
      "BBOX_STD_DEV                   [0.1 0.1 0.2 0.2]\n",
      "COMPUTE_BACKBONE_SHAPE         None\n",
      "DETECTION_MAX_INSTANCES        1000\n",
      "DETECTION_MIN_CONFIDENCE       0.3\n",
      "DETECTION_NMS_THRESHOLD        0.3\n",
      "FPN_CLASSIF_FC_LAYERS_SIZE     1024\n",
      "GPU_COUNT                      1\n",
      "GRADIENT_CLIP_NORM             5.0\n",
      "IMAGES_PER_GPU                 1\n",
      "IMAGE_CHANNEL_COUNT            3\n",
      "IMAGE_MAX_DIM                  1024\n",
      "IMAGE_META_SIZE                14\n",
      "IMAGE_MIN_DIM                  800\n",
      "IMAGE_MIN_SCALE                0\n",
      "IMAGE_RESIZE_MODE              square\n",
      "IMAGE_SHAPE                    [1024 1024    3]\n",
      "LEARNING_MOMENTUM              0.9\n",
      "LEARNING_RATE                  0.001\n",
      "LOSS_WEIGHTS                   {'rpn_class_loss': 1.0, 'rpn_bbox_loss': 1.0, 'mrcnn_class_loss': 1.0, 'mrcnn_bbox_loss': 1.0, 'mrcnn_mask_loss': 1.0}\n",
      "MASK_POOL_SIZE                 14\n",
      "MASK_SHAPE                     [28, 28]\n",
      "MAX_GT_INSTANCES               100\n",
      "MEAN_PIXEL                     [123.7 116.8 103.9]\n",
      "MINI_MASK_SHAPE                (56, 56)\n",
      "NAME                           hail\n",
      "NUMBER_OF_EPOCHS               35\n",
      "NUM_CLASSES                    2\n",
      "POOL_SIZE                      7\n",
      "POST_NMS_ROIS_INFERENCE        1000\n",
      "POST_NMS_ROIS_TRAINING         2000\n",
      "PRE_NMS_LIMIT                  6000\n",
      "ROI_POSITIVE_RATIO             0.33\n",
      "RPN_ANCHOR_RATIOS              [0.5, 1, 2]\n",
      "RPN_ANCHOR_SCALES              (32, 64, 128, 256, 512)\n",
      "RPN_ANCHOR_STRIDE              1\n",
      "RPN_BBOX_STD_DEV               [0.1 0.1 0.2 0.2]\n",
      "RPN_NMS_THRESHOLD              0.7\n",
      "RPN_TRAIN_ANCHORS_PER_IMAGE    256\n",
      "STEPS_PER_EPOCH                150\n",
      "TOP_DOWN_PYRAMID_SIZE          256\n",
      "TRAIN_BN                       False\n",
      "TRAIN_ROIS_PER_IMAGE           200\n",
      "USE_MINI_MASK                  True\n",
      "USE_RPN_ROIS                   True\n",
      "VALIDATION_STEPS               50\n",
      "WEIGHT_DECAY                   0.0001\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Override the training configurations with a few\n",
    "# changes for inferencing.\n",
    "class InferenceConfig(config.__class__):\n",
    "    # Run detection on one image at a time\n",
    "    GPU_COUNT = 1\n",
    "    IMAGES_PER_GPU = 1\n",
    "\n",
    "config = InferenceConfig()\n",
    "config.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model in inference mode\n",
    "with tf.device(DEVICE):\n",
    "    model = modellib.MaskRCNN(mode=\"inference\", model_dir=MODEL_DIR,\n",
    "                              config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading weights  /data/hailpixel_20200119/mask_rcnn_hail_final.h5\n"
     ]
    }
   ],
   "source": [
    "# Load hail training model weights\n",
    "weights_path = HAIL_WEIGHTS_PATH #model.find_last()\n",
    "print(\"Loading weights \", weights_path)\n",
    "model.load_weights(weights_path, by_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(subset_ffn):\n",
    "    #read image\n",
    "    image = skimage.io.imread(subset_ffn)\n",
    "    #run model on image\n",
    "    results  = model.detect([image], verbose=0)\n",
    "    roi_list = results[0]['rois']\n",
    "    #save back to file\n",
    "    base = os.path.basename(subset_ffn)\n",
    "    json_header = base + str(file_sz)\n",
    "    #generate json header\n",
    "    json_out = {json_header: {'filename': base,\n",
    "                   'size': file_sz,\n",
    "                   'regions':[],\n",
    "                   'file_attributes':{}\n",
    "                  }\n",
    "                }\n",
    "    #build json for every roi\n",
    "    for roi in roi_list:\n",
    "        #convert roi box to centroids\n",
    "        cx = int((roi[1] + roi[3])/2)\n",
    "        cy = int((roi[0] + roi[2])/2)\n",
    "        #generate object for json\n",
    "        json_out[json_header]['regions'].append({'shape_attributes':{'name':'point',\n",
    "                                                        'cx': cx,\n",
    "                                                        'cy': cy},\n",
    "                                    'region_attributes':{}})\n",
    "    #build json fn\n",
    "    out_fn  = base[:-3] + 'json'\n",
    "    out_ffn = '/'.join([ROI_PATH, out_fn])\n",
    "    #write to file\n",
    "    with open(out_ffn, 'w') as fp:\n",
    "        json.dump(json_out, fp)\n",
    "    #output to user\n",
    "    print('finished', base, 'with number of detections', len(roi_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished 0325.png with number of detections 233\n",
      "finished 0326.png with number of detections 232\n",
      "finished 0327.png with number of detections 220\n",
      "finished 0328.png with number of detections 232\n",
      "Finished RCNN run\n"
     ]
    }
   ],
   "source": [
    "#list subsets\n",
    "subset_ffn_list = sorted(glob.glob(SUBSET_PATH + '/*.png'))\n",
    "\n",
    "for subset_ffn in subset_ffn_list:\n",
    "    file_sz = os.path.getsize(subset_ffn)\n",
    "    #check file size\n",
    "    if file_sz/1000 < 50:\n",
    "        continue\n",
    "#     #check index number\n",
    "#     base = os.path.basename(subset_ffn)\n",
    "#     base_index = int(base[:-4])\n",
    "#     if base_index<1128:\n",
    "#         continue\n",
    "    process_image(subset_ffn) #last 1706\n",
    "\n",
    "print('Finished RCNN run')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
